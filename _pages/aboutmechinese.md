---
layout: archive
title: "徐进"
permalink: /aboutmechinese/
author_profile: true
---

徐进目前是<a href="https://iiis.tsinghua.edu.cn">清华大学交叉信息研究院</a>的四年级博士生(2018-2023)，博士生导师是<a href="http://people.iiis.tsinghua.edu.cn/~jianli">李建</a>副教授。本科毕业于<a href="https://www.bupt.edu.cn">北京邮电大学</a>通信工程专业(2014-2018, 排名1/565)，并获得北京邮电大学特等奖学金(3/1600), 后保送至清华大学交叉信息研究院。我对语音以及语言处理有着强烈的兴趣，最近主要关注面向现实应用场景的低资源语音识别与合成，NLP大规模预训练技术，自动架构搜索等方向。目前，我在KDD、NeurIPS等国际人工智能顶级会议上发表论文10篇，其中第一作者4篇。

Internship
======

* <i>2019.09 - 2020.10</i> Microsoft Research Asia. Full-time Research Intern, Supervisor: Xu Tan, Tao Qin
* <i>2018.07 - 2019.02</i> Baidu Business Intelligence Lab. Full-time Research Intern, Supervisor: Jingbo Zhou, Hui Xiong

Publications & Preprints
======

2022
-----

<style>
td, th {
   border: none!important;
}
</style>

<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	Analyzing and Mitigating Interference in Neural Architecture Search
        </b>
        <br>
		<i>
        	Arxiv Preprint
        </i>
        <br>
	    	<b>Jin Xu</b>, Xu Tan, Kaitao Song, Renqian Luo, Yichong Leng, Tao Qin, Tie-Yan Liu, Jian Li
        <br>
		[<a href="https://arxiv.org/abs/2108.12821">PDF</a>]
		</div>
	</td></tr></tbody>
</table>


<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	AutoHEnsGNN: Winning Solution to AutoGraph Challenge for KDD Cup 2020
        </b>
        <br>
		<i>
        	ICDE 2022
        </i>
        <br>
	    	<b>Jin Xu*</b>, Mingjian Chen*, Jianqiang Huang, Xingyuan Tang, Ke Hu, Jian Li, Jia Cheng, Jun Lei
        <br>
		[<a href="https://arxiv.org/abs/2111.12952">PDF</a>]
		</div>
	</td></tr></tbody>
</table>


<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition
        </b>
        <br>
		<i>
        	EMNLP 2022 Findings
        </i>
        <br>
	    	Yichong Leng, Xu Tan, Rui Wang, Linchen Zhu, <b>Jin Xu</b>, Wenjie Liu, Linquan Liu, Xiang-Yang Li, Tao Qin, Edward Lin, Tie-Yan Liu
        <br>
		[<a href="https://aclanthology.org/2021.findings-emnlp.367/">PDF</a>]
		</div>
	</td></tr></tbody>
</table>

<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition
        </b>
        <br>
		<i>
        	NeurIPS 2022
        </i>
        <br>
	    	Yichong Leng, Xu Tan, Linchen Zhu, <b>Jin Xu</b>, Renqian Luo, Linquan Liu, Tao Qin, Xiang-Yang Li, Ed Lin, Tie-Yan Liu
        <br>
		[<a href="https://proceedings.neurips.cc/paper/2021/file/b597460c506e8e35fb0cc1c1905dd3bc-Paper.pdf">PDF</a>]
		</div>
	</td></tr></tbody>
</table>


<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	Speech-T: Transducer for Text to Speech and Beyond
        </b>
        <br>
		<i>
        	NeurIPS 2022
        </i>
        <br>
	    	Jiawei Chen, Xu Tan, Yichong Leng, <b>Jin Xu</b>, Guihua Wen, Tao Qin, Tie-Yan Liu
        <br>
		[<a href="https://proceedings.neurips.cc/paper/2021/hash/344ef5151be171062f42f03e69663ecf-Abstract.html">PDF</a>]
		</div>
	</td></tr></tbody>
</table>


2021
-----


<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search
        </b>
        <br>
		<i>
        	KDD 2021
        </i>
        <br>
	    	<b>Jin Xu</b>, Xu Tan, Renqian Luo, Kaitao Song, Jian Li, Tao Qin, Tie-Yan Liu
        <br>
		[<a href="https://dl.acm.org/doi/10.1145/3447548.3467262">PDF</a>]
		</div>
	</td></tr></tbody>
</table>

<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	MixSpeech: Data Augmentation for Low-resource Automatic Speech Recognition
        </b>
        <br>
		<i>
        	ICASSP 2021
        </i>
        <br>
	    	Linghui Meng, <b>Jin Xu</b>, Xu Tan, Jindong Wang, Tao Qin, Bo Xu
        <br>
		[<a href="https://arxiv.org/abs/2102.12664">PDF</a>]
		</div>
	</td></tr></tbody>
</table>

<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/symbiosis.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
		<b>
			Effective Graph Learning with Adaptive Knowledge Exchange
        </b>
        <br>
		<i>
        	Arxiv Preprint
        </i>
        <br>
	    	Liang Zeng*, <b>Jin Xu*</b>, Zijun Yao, Yanqiao Zhu, Jian Li
        <br>
		[<a href="https://arxiv.org/abs/2106.05455">PDF</a>]
		</div>
	</td></tr></tbody>
</table>

2020
-----
<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	An Adaptive Master-Slave Regularized Model for Unexpected Revenue Prediction Enhanced with Alternative Data
        </b>
        <br>
		<i>
        	ICDE 2020
        </i>
        <br>
	    	<b>Jin Xu</b>, Jingbo Zhou, Yongpo Jia, Jian Li, Xiong Hui
        <br>
		[<a href="https://ieeexplore.ieee.org/abstract/document/9101395">PDF</a>]
		</div>
	</td></tr></tbody>
</table>


<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://Jxu-Thu.github.io/images/pub/multispeech.jpg" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	Multispeech: Multi-speaker text to speech with transformer
        </b>
        <br>
		<i>
        	InterSpeech 2020
        </i>
        <br>
	    	Mingjian Chen, Xu Tan, Yi Ren, <b>Jin Xu</b>, Hao Sun, Sheng Zhao, Tao Qin, Tie-Yan Liu
        <br>
		[<a href="https://indico2.conference4me.psnc.pl/event/35/contributions/3867/attachments/794/832/Thu-1-11-11.pdf">PDF</a>]
		</div>
	</td></tr></tbody>
</table>

2019
-----

<table style="border: none!important;">
	  <tbody><tr><td style="width:230px; height:110px" valign="middle" align="middle">
	    <img src="http://transirius.github.io/images/pub/kat.png" width="250">
	  </td>
	  <td style="width:10px">
	  </td>
	  <td valign="middle">
	    <div>
	    	<b>
        	A collaborative learning framework to tag refinement for points of interest
        </b>
        <br>
		<i>
        	KDD 2019
        </i>
        <br>
	    	Jingbo Zhou, Shan Gou, Renjun Hu, Dongxiang Zhang, <b>Jin Xu</b>, Airong Jiang, Ying Li, Hui Xiong
        <br>
		[<a href="https://dl.acm.org/doi/abs/10.1145/3292500.3330698">PDF</a>]
		</div>
	</td></tr></tbody>
</table>

